---
title: "Word Prediction Model"
date: "11/07/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(quanteda)
library(tm)
library(data.table)
library(textclean)
library(ngram)
library(tictoc)
library(ff)
library(ffbase)
#library(sqldf)
```

```{r}
source("./Word_Prediction/Functions.R")
```

```{r}
filepath <- "./Word_Prediction/datatables_min.csv"
classes <- c("character", "character", "numeric")

gc(
test <- fread(filepath, header = TRUE, sep = ",", stringsAsFactors = FALSE, nrow = 1, colClasses = classes))
```


```{r}
input <- "now another way to"
```


```{r}
phrase_input <- input_adj(input)
phrase_input
```

```{r}
#Adjust input
phrase <- input %>%
  tolower() %>%
  replace_contraction() %>%
  str_replace_all("haven't", "have not") %>%
  str_replace_all("hadn't", "had not") %>%
  removePunctuation()

m <- str_count(phrase, " "); m
q <- min(m, 5)
phrase_input <- paste(word(phrase,-q:-1), collapse = " "); phrase
phrase_input
```

```{r}
 ngram_table <- read.table.ffdf(file = "./Word_Prediction/datatables_min.csv", sep = ",",
                                  header = TRUE, nrows = 1000, #0000,
                                 # first.row = 10, next.rows = 1000000,
                                  colClasses = c("factor", "factor", "numeric"))
```

```{r}
tic("csv")
#ngram_table <- data.table::fread("./Word_Prediction/data/datatables_min.csv")  #, header = T,colClasses = c("character","character", "numeric"))
toc()

#tic("rds")
#ngram_table <- readRDS("./Word_Prediction/data/datatables_min.RDS")
#toc()
```

```{r}
tic("min4")
datatables_min4 <- readRDS("./Word_Prediction/data/datatables_min4.RDS")
toc()
```
```{r}
table <- table_2
table1 <- table[1:500]
table2 <- table[600:800]
table3 <- table[1000:1500]
table4 <- table[5000:5400]
```



```{r}
input <- "who let us know that their either have"
str_count(input, " ")
```


```{r}
phrase_input <- input_adj(input)
phrase_input
```

```{r}
x <- predict_word(ngram_table, phrase_input)
x
```

```{r}
gc()
tic("test")
table <- sub_table
phrase <- phrase_input
print(phrase)

#setkey(table, ngram_1)

#ind <- table[phrase, nomatch = 0]
ind <- table[grep(paste0("^",phrase,"$"), ngram_1)]
while(NROW(ind) == 0){
 
 phrase <- str_replace(phrase, paste0("^", word(phrase,1), " "), "")
 print(phrase)
 ind <- table[grep(paste0("^",phrase,"$"), ngram_1)]
 
}
print(ind)
pred_word <- ind$pred; pred_word
toc()
```


```{r}
u <- ngram_table[1:10]
u
```

```{r}

#df <- as.data.frame(u)
#hash(u)
```


```{r}

```

```{r}
phrase <- phrase_input

#Obtain lines from the data table with the last few words of ngram_1 matching the phrase
sub_lines <- ngram_table[grep(paste0(" ", phrase,"$"), ngram_1)]
print(sub_lines)

loop <- 1
len_phrase <- wordcount(phrase); len_phrase

#If there are no matches
while(NROW(sub_lines) == 0) {
  
  #Remove the last word from the phrase
  phrase <- str_replace(phrase, paste0("^", word(phrase,1), " "), "")
  sub_lines <- ngram_table[grep(paste0(" ", phrase,"$"), ngram_1)]
  print(phrase)
  
  loop <- loop + 1
  
  #Stop if the loop equals the length of the phrase
  if(loop == len_phrase){
    break
  }
  
}

print(sub_lines)

if(NROW(sub_lines) == 0){
  
  stop("No prediction found")
  
}

options <- sub_lines %>%
  group_by(pred) %>%
  summarise(tot_freq = sum(freq)) %>%
  ungroup() %>%
  arrange(desc(tot_freq))

predicted_word <- options[1,1] %>% pull()

print(options)

```

```{r}
sub_lines <- ngram_table[grep(paste0(" ", phrase_input,"$"), ngram_1)]
sub_lines
sub_lines <- ngram_table[grep(paste0(" ", phrase,"$"), ngram_1)]
sub_lines
```

##ffdf save and load

```{r}
ngram_ffdf <- read.table.ffdf(file = "./Word_Prediction/datatables_min.csv", sep = ",",
                                  header = TRUE, nrows = 20000000,
                                  first.row = 1000000, next.rows = 1000000,
                                  colClasses = c("factor", "factor", "numeric"))

save.ffdf(ngram_ffdf, dir = "./Word_Prediction/ffdb")
```


```{r}
#save.ffdf(ngram_ffdf, dir = "./Word_Prediction/ffdb")
```

```{r}
rm(ngram_ffdf
```
```{r}
load.ffdf("./Word_Prediction/ffdb")
```


```{r}
 system.time(ngram_table <- read.table.ffdf(file = "./Word_Prediction/datatables_min.csv", sep = ",",
                                  header = TRUE, nrows = 1000000,
                                  first.row = 1000, next.rows = 100000,
                                  colClasses = c("factor", "factor", "numeric")))
```

```{r}
ngram_dt <- readRDS("./useful files/datatables_min.RDS")
```

```{r}
head(ngram_dt)
```

```{r}
ngram_dt2 <- ngram_dt %>% mutate_at(vars("pred", "ngram_1"), as.factor)
```

```{r}
saveRDS(ngram_dt2,"./useful files/ngram_dt_min_as_factors")
```


```{r}
ngram_sub <- ngram_dt[1:1000]
ngram_sub2 <- ngram_sub %>% mutate_at(vars("pred", "ngram_1"), as.factor)
```

```{r}
ngram_ffdf <- as.ffdf(ngram_dt2)
```

```{r}
save.ffdf(ngram_ffdf, dir = "./Word_Prediction/data")
```

```{r}
rm(ngram_ffdf)
```


```{r}
load.ffdf("./Word_Prediction/data")
```

```{r}
tab1 <- ngram_ffdf[1:10000,]
tab2 <- ngram_ffdf[20000:30000,]
```

```{r}
tab1ff <- as.ffdf(tab1)
```

```{r}
tab2ff <- as.ffdf(tab2)
```

```{r}
ffdfbind <- rbind(tab1ff, tab2ff)
```

